{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regularized logistic regression to classify email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Penalty experiments -----------\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-4.86311352] [[ -2.74146099e-02  -2.25297669e-01   1.21840891e-01   2.29362945e+00\n",
      "    2.70425725e-01   2.32851140e-01   9.28595397e-01   2.95200209e-01\n",
      "    1.62205927e-01   6.78259308e-02  -8.32603904e-02  -1.60373349e-01\n",
      "   -4.72247939e-02   1.07676991e-02   1.87903695e-01   8.19771795e-01\n",
      "    5.09529020e-01   3.98710975e-02   2.67729674e-01   3.47047342e-01\n",
      "    2.60498933e-01   3.64605628e-01   7.25019798e-01   1.96728233e-01\n",
      "   -3.15395709e+00  -4.03133841e-01  -1.25451038e+01  -6.16577226e-02\n",
      "   -1.56114586e+00  -5.51430615e-02  -3.00821906e-02   4.07263767e-01\n",
      "   -3.68156508e-01  -1.43611895e+00  -5.87181904e-01   4.44294672e-01\n",
      "    4.23159741e-02  -1.56897099e-01  -4.55330705e-01  -1.02250227e-01\n",
      "   -3.54273314e+00  -1.72944439e+00  -4.37529465e-01  -1.05999940e+00\n",
      "   -9.18599267e-01  -1.75490296e+00  -1.67475819e-01  -9.56875669e-01\n",
      "   -3.65653393e-01  -1.36535580e-01  -6.58692608e-02   2.06714067e-01\n",
      "    1.70694409e+00   1.21460293e+00  -3.35270257e-01   1.56141546e+00\n",
      "    3.68775545e-01]]\n",
      "Accuracy on set aside test set for  std  =  0.9296875\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-1.57064952] [[-0.1726611  -0.04367715 -0.12698213  1.27211501  0.47273572  0.27123641\n",
      "   0.96061652  0.47973532  0.11129563  0.1528317  -0.1036234  -0.17832528\n",
      "  -0.3347042   0.23747613  0.42000152  0.51149919  0.60034288 -0.11495911\n",
      "   0.12177644  0.30439481  0.21347759  0.19040822  0.5556553   0.552003\n",
      "  -1.36072835  0.07658677 -3.5632057   0.25179199 -0.21039516  0.07550703\n",
      "   0.38269363  1.04386234 -0.15960133  1.35217406 -0.44850832  0.48667893\n",
      "  -0.35948425  0.34240062 -0.32463741  0.03204544 -0.33525171 -0.92965522\n",
      "  -0.67078938 -0.81491402 -0.44647069 -0.93612217  0.15324218 -0.83701328\n",
      "  -0.42637632 -0.13230697  0.19983665  0.78470633  1.46925101  0.03196938\n",
      "   0.705321    0.04976234  0.36434553]]\n",
      "Accuracy on set aside test set for  logt  =  0.94140625\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-1.77215713] [[-0.27014955 -0.1365251  -0.4410508   0.19592951  1.09940129  0.28382773\n",
      "   2.39370507  0.89848441  0.26534444  0.43563221 -0.3972686  -0.42883219\n",
      "  -1.07464529  0.32304241  0.66669496  1.58604188  1.1034645  -0.17358442\n",
      "   0.24915859  0.76718397  0.78417514  1.42475347  1.03883445  1.61862499\n",
      "  -2.93736492 -0.23318222 -5.85001975  1.26265999 -0.83078572 -0.06707944\n",
      "  -1.65514222 -1.71955785 -0.92717928  0.44740972 -0.7394178   0.51820559\n",
      "  -1.06392119  1.07669275 -0.98242948 -0.32996126 -2.9696163  -2.53985702\n",
      "  -1.21091092 -2.16548824 -0.85214311 -2.56733552  0.03485934 -2.02740042\n",
      "  -0.37388424  0.22126841 -0.21524125  1.27340468  1.59564491 -0.03239022\n",
      "  -0.04453251 -0.04453251 -0.04453251]]\n",
      "Accuracy on set aside test set for  bin  =  0.92578125\n",
      "L1 Penalty experiments -----------\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-13.8780315] [[ -5.55347630e-02  -1.99435087e-01   1.09856681e-01   2.79024038e+00\n",
      "    2.67927337e-01   2.65861242e-01   8.93476571e-01   2.98051102e-01\n",
      "    2.52538850e-01   6.80234788e-02  -6.81787715e-02  -1.52440149e-01\n",
      "   -3.63118634e-02   1.88940828e-02   1.60871871e-01   7.96622098e-01\n",
      "    5.51828642e-01   3.45635472e-02   2.69309864e-01   3.38355136e-01\n",
      "    2.50734542e-01   3.25872832e-01   6.96301758e-01   1.72514552e-01\n",
      "   -3.23538048e+00  -3.10473978e-01  -5.25251617e+01  -6.16527785e-02\n",
      "   -1.46860746e+00  -1.44743587e-02   1.95392529e-01   4.93659579e-01\n",
      "   -3.24773681e-01  -3.64971540e-01  -7.58615197e-01   4.30132723e-01\n",
      "    6.11867270e-02  -1.55711306e-01  -4.54569582e-01  -4.31432153e-02\n",
      "   -5.87341586e+00  -1.89170358e+00  -5.41889232e-01  -1.01151358e+00\n",
      "   -9.19137119e-01  -1.77127923e+00  -1.72327734e-01  -1.22819164e+00\n",
      "   -3.47419302e-01  -1.38085410e-01  -5.44583869e-02   1.97370832e-01\n",
      "    1.71552672e+00   1.08058988e+00   3.63629886e-01   2.64721566e+00\n",
      "    3.18266951e-01]]\n",
      "Accuracy on set aside test set for  std  =  0.923828125\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-12.46565893] [[ -1.99354092e-01  -6.38319627e-02  -1.32710237e-01   4.02596477e-01\n",
      "    4.57329464e-01   2.20843868e-01   9.56360399e-01   4.54097312e-01\n",
      "    4.87692215e-02   1.53560533e-01  -1.50584455e-01  -1.91663317e-01\n",
      "   -3.54222985e-01   2.11504523e-01   2.90078344e-01   5.08368848e-01\n",
      "    5.87757504e-01  -1.26469708e-01   1.20532807e-01   2.21143140e-01\n",
      "    2.18971921e-01   1.38991398e-01   5.38968191e-01   5.27787526e-01\n",
      "   -1.32580815e+00   3.22752569e-02  -3.55713115e+00   2.34381829e-01\n",
      "   -3.49649563e-01   0.00000000e+00   2.01686517e-01   3.63538950e-01\n",
      "   -2.08159235e-01   1.12304278e+00  -4.38348690e-01   4.77597882e-01\n",
      "   -3.78301018e-01   2.68703930e-01  -3.64503614e-01  -3.32449968e-02\n",
      "   -6.77674754e-01  -1.06525847e+00  -8.99776490e-01  -9.06224031e-01\n",
      "   -4.69422453e-01  -9.82442294e-01  -1.34149856e-02  -1.08550877e+00\n",
      "   -4.36766922e-01  -1.34068446e-01   0.00000000e+00   7.60229014e-01\n",
      "    1.41773626e+00  -1.75272975e-05   6.42349107e-01   6.43723436e-02\n",
      "    4.47705222e-01]]\n",
      "Accuracy on set aside test set for  logt  =  0.942057291667\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-0.66716097] [[-0.27336064 -0.12126456 -0.43712568  0.13370788  1.10354463  0.2991534\n",
      "   2.4201706   0.90441729  0.26764199  0.44622667 -0.41160451 -0.42683932\n",
      "  -1.09404547  0.31945049  0.66142301  1.59478583  1.13576897 -0.18202475\n",
      "   0.2407225   0.80245764  0.78857678  1.41367358  1.03793951  1.65683678\n",
      "  -3.01171029 -0.19607191 -6.22044884  1.30756883 -0.83069935 -0.03996928\n",
      "  -1.73908533 -1.90107013 -0.94449599  0.20416451 -0.72627276  0.52614774\n",
      "  -1.05149919  1.10788797 -0.99640215 -0.30686496 -4.06521968 -2.61211681\n",
      "  -1.25473789 -2.21893402 -0.86092139 -2.58682822  0.         -2.10740039\n",
      "  -0.3809217   0.21928979 -0.20785994  1.28200536  1.61370222 -0.02056847\n",
      "  -0.27292539 -0.17302552 -0.79616352]]\n",
      "Accuracy on set aside test set for  bin  =  0.92578125\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import utils\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "# No modifications in this script\n",
    "# complete the functions in util.py; then run the script\n",
    "\n",
    "# load the spam data in\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = utils.load_spam_data()\n",
    "\n",
    "# Preprocess the data \n",
    "\n",
    "Xtrain_std,mu,sigma = utils.std_features(Xtrain)\n",
    "Xtrain_logt = utils.log_features(Xtrain)\n",
    "Xtrain_bin = utils.bin_features(Xtrain)\n",
    "\n",
    "Xtest_std = (Xtest - mu)/sigma\n",
    "Xtest_logt = utils.log_features(Xtest)\n",
    "Xtest_bin = utils.bin_features(Xtest)\n",
    "\n",
    "# find good lambda by cross validation for these three sets\n",
    "\n",
    "def run_dataset(X,ytrain,Xt,ytest,type,penalty):\n",
    "\n",
    "    best_lambda = utils.select_lambda_crossval(X,ytrain,0.1,5.1,0.5,penalty)\n",
    "    print \"best_lambda = \", best_lambda\n",
    "\n",
    "    # train a classifier on best_lambda and run it\n",
    "    if penalty == \"l2\":\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='lbfgs',fit_intercept=True)\n",
    "    else:\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='liblinear',fit_intercept=True)\n",
    "    lreg.fit(X,ytrain)\n",
    "    print \"Coefficients = \", lreg.intercept_,lreg.coef_\n",
    "    predy = lreg.predict(Xt)\n",
    "    print \"Accuracy on set aside test set for \", type, \" = \", np.mean(predy==ytest)\n",
    "\n",
    "print \"L2 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l2\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l2\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l2\")\n",
    "\n",
    "print \"L1 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l1\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l1\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
