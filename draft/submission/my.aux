\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Locally weighted linear regression}{1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Calculating $\theta $ by Batch Gradient Descent}}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Properties of the linear regression estimator}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Problem 3.1 Implementing linear regression}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Implementing linear regression with one variable}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Problem 3.1 A1Computing the cost function J($\theta $)}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Plotting the data}}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Fitting a linear model to the data in fig 1}}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces convergence of gradient }}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Problem 3.1 A2 Implmenting gradient descent}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Problem 3.1 A3 Predicting on unseen data}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}assessing model quality}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Problem 3.1 B Linear regression with multiple variables}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Problem 3.1 B1Feature normalization}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8}Problem 3.1 B2 Loss function and gradient descent}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Surface plot of J}}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces contour plot of J}}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces J for multiple variables}}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9}Problem 3.1 B3 Making predictions on unseen data}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10}Problem 3.1 B4 Normal equation}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.11}Problem 3.1 B5 Convergence of gradient descent}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces J for different learning rate}}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces J for different learning rate}}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces J for different learning rate}}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces J for different learning rate}}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces JThe training data}}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Problem 3 part 2 Implementing regularized linear regression}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Problem 3.2 A1 regression cost function }{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Problem 3.2 A2 Gradient of the cost function }{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Problem 3.2 A3 Learning curve}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Learning polynomial regression models}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Problem 3.2 A4 Adjusting the regularization parameter}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Problem 3.2 A5 selecting lambda using a validation set}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The best fit for the data}}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Learning curves}}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Polynomial fit for reg=0 with p=6}}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Learning curves for reg=0}}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Polynomial fit for reg=1}}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Learning curves for reg=1}}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Polynomial fit for reg=10}}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Learning curves for reg=10}}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Polynomial fit for reg=100}}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Learning curves for reg=100}}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Selecting lambda}}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Problem 3.2 A6 Test error with the best model}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8}Problem 3.2 A6 Test error with the best model}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9}Problem 3.2 A7 Plotting learning curves with randomly examples}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Test error with the best model}}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Test error with the best model}}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Averaged Learning curve for lambda=1}}{17}}
